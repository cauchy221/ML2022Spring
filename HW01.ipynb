{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW01.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1I_mx2pTZTu8-dfkjbLaJv28PJWkbziD8",
      "authorship_tag": "ABX9TyMBzBwM4nsU4v3ILjBuNVwJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cauchy221/ML2022Spring/blob/main/HW01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Homework 1: COVID-19 Cases Prediction (Regression)**"
      ],
      "metadata": {
        "id": "kuc2PWX7G50g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download data\n",
        "Download it from the Google driver links below, or from Kaggle then upload data manually to the workspace."
      ],
      "metadata": {
        "id": "iNUO74QcHUVn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-259DsNfSAJa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f64bf674-8a34-4497-8cdc-f592abb8c87f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1kLSW_-cW2Huj7bh84YTdimGBOJaODiOS\n",
            "To: /content/covid.train.csv\n",
            "100% 2.49M/2.49M [00:00<00:00, 160MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1iiI5qROrAhZn-o4FPqsE97bMzDEFvIdg\n",
            "To: /content/covid.test.csv\n",
            "100% 993k/993k [00:00<00:00, 75.0MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown --id '1kLSW_-cW2Huj7bh84YTdimGBOJaODiOS' --output covid.train.csv\n",
        "!gdown --id '1iiI5qROrAhZn-o4FPqsE97bMzDEFvIdg' --output covid.test.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import packages\n",
        "Import all packages that are needed."
      ],
      "metadata": {
        "id": "rB-N9PU1IRwj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Numerical Operations\n",
        "import math\n",
        "import numpy as np\n",
        "\n",
        "# Reading/Writing Data\n",
        "import pandas as pd\n",
        "import os\n",
        "import csv\n",
        "\n",
        "# Show Trianing Process in Progress Bar\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Pytorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, random_split  # can split training dataset into trining and validation\n",
        "\n",
        "# For Plotting Learning Curve\n",
        "from torch.utils.tensorboard import SummaryWriter"
      ],
      "metadata": {
        "id": "BetctE8bIHaO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Some Utility Functions\n",
        "Don't have to modify this part but have to understand the usage of each function."
      ],
      "metadata": {
        "id": "gMjxjcCzWvE2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.random.mtrand import triangular\n",
        "def same_seed(seed):\n",
        "  '''Fix random number generator seeds for reproducibility.'''\n",
        "  torch.backends.cudnn.deterministic = True  # if true, the convolutional algorithm is the same each time\n",
        "  torch.backends.cudnn.benchmark = False  # if true, auto-tuner in cuDNN will find the most efficient algorithm each time automatically\n",
        "  np.random.seed(seed)  # generate the same random number with the same seed\n",
        "  torch.manual_seed(seed)  # set the seed for generating random numbers\n",
        "  if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(seed)  # set the seed for generating random numbers on all GPUs\n",
        "\n",
        "def train_valid_split(data_set, valid_ratio, seed):\n",
        "  '''Split provided training data into training set and validation set'''\n",
        "  valid_set_size = int(valid_ratio * len(data_set))\n",
        "  train_set_size = len(data_set) - valid_set_size\n",
        "  train_set, valid_set = random_split(data_set, [train_set_size, valid_set_size], generator=torch.Generator().manual_seed(seed))\n",
        "  return np.array(train_set), np.array(valid_set)  # return in np.array\n",
        "\n",
        "def predict(test_loader, model, device):\n",
        "  '''Get model prediction'''\n",
        "  model.eval()  # set the model to evaluation mode\n",
        "  preds = []\n",
        "  for x in tqdm(test_loader):  # tqdm(iterator)\n",
        "    x = x.to(device)\n",
        "    with torch.no_grad():\n",
        "      pred = model(x)  # it's on device right now\n",
        "      preds.append(pred.detach().cpu())\n",
        "  preds = torch.cat(preds, dim=0).numpy()\n",
        "  return preds"
      ],
      "metadata": {
        "id": "m9VIFDgSXCCJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ],
      "metadata": {
        "id": "LZiCMUVJjnVc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class COVID19Dataset(Dataset):\n",
        "  '''\n",
        "  x: Features\n",
        "  y: Targets, if none, do prediction\n",
        "  '''\n",
        "  def __init__(self, x, y=None):\n",
        "    if y is None:\n",
        "      self.y = y\n",
        "    else:\n",
        "      self.y = torch.FloatTensor(y)\n",
        "    self.x = torch.FloatTensor(x)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    if self.y is None:\n",
        "      return self.x[idx]\n",
        "    else:\n",
        "      return self.x[idx], self.y[idx]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.x)"
      ],
      "metadata": {
        "id": "1LpJNtJjjkx6"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Neural Network Model\n",
        "Try out different model architectures by modifying the class below"
      ],
      "metadata": {
        "id": "4xe3T_ehlGqa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class My_Model(nn.Module):\n",
        "  def __init__(self, input_dim):\n",
        "    super(My_Model, self).__init__()\n",
        "    # TODO: modify model's structure, be aware of dimensions\n",
        "    # 2022/3/3 Try default structure with default input_dim\n",
        "    self.layers = nn.Sequential(\n",
        "        nn.Linear(input_dim, 16), \n",
        "        nn.ReLU(), \n",
        "        nn.Linear(16, 8), \n",
        "        nn.ReLU(), \n",
        "        nn.Linear(8, 1)\n",
        "    )\n",
        "  \n",
        "  def forward(self, x):\n",
        "    x = self.layers(x)\n",
        "    x = x.squeeze(1)  # (B, 1) -> (B)\n",
        "    return x"
      ],
      "metadata": {
        "id": "DK7BkZvGlFxD"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Selection\n",
        "Not all features are useful. Carefully choose them by modifying the function below."
      ],
      "metadata": {
        "id": "A9KBo_kloX2t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def select_feat(train_data, valid_data, test_data, select_all=True):\n",
        "  '''Select useful features'''\n",
        "  y_train, y_valid = train_data[:,-1], valid_data[:,-1]\n",
        "  raw_x_train, raw_x_valid, raw_x_test = train_data[:,:-1], valid_data[:,:-1], test_data[:,:-1]\n",
        "\n",
        "  if select_all:\n",
        "    feat_idx = list(range(raw_x_train.shape[1]))\n",
        "  else:\n",
        "    feat_idx = [0,1,2,3,4,5] # TODO: Select suitable columns\n",
        "  \n",
        "  return raw_x_train[:,feat_idx], raw_x_valid[:,feat_idx], raw_x_test[:,feat_idx], y_train, y_valid"
      ],
      "metadata": {
        "id": "uD7mzJJQoSVU"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Loop"
      ],
      "metadata": {
        "id": "wdHXjcY1w6_p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def trainer(train_loader, valid_loader, model, config, device):\n",
        "  criterion = nn.MSELoss(reduction='mean')  # loss function\n",
        "\n",
        "  # define optimization algorithm\n",
        "  # "
      ],
      "metadata": {
        "id": "fzBhLwItw6FC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}